\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\@writefile{toc}{\contentsline {section}{\numberline {1}Question 1}{1}{section.1}\protected@file@percent }
\newlabel{eq:Q1_model}{{1}{1}{Question 1}{equation.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The observed $x$ data for Question 1.\relax }}{1}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Q1_data}{{1}{1}{The observed $x$ data for Question 1.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Part A: Grid-based Bayesian inference}{1}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.1}The prior distribution}{2}{subsubsection.1.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The prior distribution function $p(\theta )$ visualised over the domain $\theta \in [-10, 20]$.\relax }}{2}{figure.caption.3}\protected@file@percent }
\newlabel{fig:Q1a_prior}{{2}{2}{The prior distribution function $p(\theta )$ visualised over the domain $\theta \in [-10, 20]$.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.2}The generative model and the likelihood function}{2}{subsubsection.1.1.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The likelihood function $\mathcal  {L}(\mathbf  {x}, \theta )$ of the generative model $p(x \vert \theta )$ over the domain $\theta \in [-10, 20]$. In a) the likelihood function is shown, and in b) the log-likelihood function is shown.\relax }}{3}{figure.caption.4}\protected@file@percent }
\newlabel{fig:Q1a_likelihood}{{3}{3}{The likelihood function $\mathcal {L}(\mathbf {x}, \theta )$ of the generative model $p(x \vert \theta )$ over the domain $\theta \in [-10, 20]$. In a) the likelihood function is shown, and in b) the log-likelihood function is shown.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.3}The unnormalised posterior}{3}{subsubsection.1.1.3}\protected@file@percent }
\newlabel{eq:Q1_Bayes}{{8}{3}{The unnormalised posterior}{equation.1.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The unnormalised posterior distribution $\mathcal  {F}(\theta , \mathbf  {x}, \sigma , \mu _\theta , b)$ for $\sigma =1.5, \mu _\theta = 0$ and $b = 2$ over the domain $\theta \in [-10, 20]$. Three variations of the unnormalised posterior is visualised here, the standard unnormalised posterior, the logarithm of the unnormalised posterior and the terms therein, and the negative of the unnormalised log-posterior.\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:Q1a_unnorm_posterior}{{4}{4}{The unnormalised posterior distribution $\mathcal {F}(\theta , \mathbf {x}, \sigma , \mu _\theta , b)$ for $\sigma =1.5, \mu _\theta = 0$ and $b = 2$ over the domain $\theta \in [-10, 20]$. Three variations of the unnormalised posterior is visualised here, the standard unnormalised posterior, the logarithm of the unnormalised posterior and the terms therein, and the negative of the unnormalised log-posterior.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.4}The model evidence}{4}{subsubsection.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.5}The posterior distribution}{4}{subsubsection.1.1.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The posterior distribution $p(\theta \vert \mathbf  {x})$ and the logarithm thereof over the domain $\theta \in [-10, 20]$. The MAP solution is given in Table \ref  {tab:Q1_a}.\relax }}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:Q1a_posterior}{{5}{5}{The posterior distribution $p(\theta \vert \mathbf {x})$ and the logarithm thereof over the domain $\theta \in [-10, 20]$. The MAP solution is given in Table \ref {tab:Q1_a}.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.6}The posterior predictive distribution}{5}{subsubsection.1.1.6}\protected@file@percent }
\newlabel{eq:Q1a_posterior}{{12}{5}{The posterior predictive distribution}{equation.1.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.7}Estimating estimators}{5}{subsubsection.1.1.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The posterior predictive distribution $p(x \vert \mathbf  {x})$ determined using a cheap and expensive computational methodology over the domain $\theta \in [-10, 20]$.\relax }}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:Q1a_posterior_predictive}{{6}{6}{The posterior predictive distribution $p(x \vert \mathbf {x})$ determined using a cheap and expensive computational methodology over the domain $\theta \in [-10, 20]$.\relax }{figure.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The estimates for the unknown parameter $\theta $ using the prior, maximum likelihood and maximum a posteriori. These estimates are found using a grid-based approach, analytically and through numerical optimisation.\relax }}{6}{table.caption.8}\protected@file@percent }
\newlabel{tab:Q1_a}{{1}{6}{The estimates for the unknown parameter $\theta $ using the prior, maximum likelihood and maximum a posteriori. These estimates are found using a grid-based approach, analytically and through numerical optimisation.\relax }{table.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.8}Using Bayesian inference}{6}{subsubsection.1.1.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.1.9}Prior hyper-parameters}{6}{subsubsection.1.1.9}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The CDFs used to determine the probabilities $p(\theta \leq 4 \vert \mathbf  {x})$ and $p(x \leq 4 \vert \mathbf  {x})$ over the domain $\theta \in [-10, 20]$. In a) the CDF of the posterior distribution $p(\theta \vert \mathbf  {x})$ is shown, while in b) the CDF of the posterior predictive distribution $p(x \vert \mathbf  {x})$ is shown.\relax }}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:Q1a_CDFs}{{7}{7}{The CDFs used to determine the probabilities $p(\theta \leq 4 \vert \mathbf {x})$ and $p(x \leq 4 \vert \mathbf {x})$ over the domain $\theta \in [-10, 20]$. In a) the CDF of the posterior distribution $p(\theta \vert \mathbf {x})$ is shown, while in b) the CDF of the posterior predictive distribution $p(x \vert \mathbf {x})$ is shown.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Part B: Conjugate Bayesian inference}{7}{subsection.1.2}\protected@file@percent }
\newlabel{eq:Q1b_model}{{17}{7}{Part B: Conjugate Bayesian inference}{equation.1.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The influence of the prior variance $p(\theta \vert \alpha ) = L(\theta \vert 0, \alpha )$ on the Bayesian inference process. In a) the prior is visualised over $\alpha $, in b) the variation of the MAP estimate for $\theta $ is shown, in c) the model evidence variation in shown, and in d) the variation of the posterior $p(\theta \vert \mathbf  {x})$ is shown.\relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:Q1a_alpha_variation}{{8}{8}{The influence of the prior variance $p(\theta \vert \alpha ) = L(\theta \vert 0, \alpha )$ on the Bayesian inference process. In a) the prior is visualised over $\alpha $, in b) the variation of the MAP estimate for $\theta $ is shown, in c) the model evidence variation in shown, and in d) the variation of the posterior $p(\theta \vert \mathbf {x})$ is shown.\relax }{figure.caption.10}{}}
\newlabel{eq:Q1b_proportion}{{20}{8}{Part B: Conjugate Bayesian inference}{equation.1.20}{}}
\newlabel{eq:theta_update}{{28}{9}{Part B: Conjugate Bayesian inference}{equation.1.28}{}}
\newlabel{eq:beta_update}{{29}{9}{Part B: Conjugate Bayesian inference}{equation.1.29}{}}
\newlabel{eq:a_update}{{30}{9}{Part B: Conjugate Bayesian inference}{equation.1.30}{}}
\newlabel{eq:b_update}{{31}{9}{Part B: Conjugate Bayesian inference}{equation.1.31}{}}
\newlabel{eq:Q1b_marginal_theta}{{32}{9}{Part B: Conjugate Bayesian inference}{equation.1.32}{}}
\newlabel{eq:Q1b_marginal_lambda}{{33}{9}{Part B: Conjugate Bayesian inference}{equation.1.33}{}}
\newlabel{eq:Q1b_posterior_predict}{{36}{9}{Part B: Conjugate Bayesian inference}{equation.1.36}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}Maximum likelihood estimation}{10}{subsubsection.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.2}Bayesian inference}{10}{subsubsection.1.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The Normal-Gamma prior under different hyper-parameter initialisations.\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:Q1b_prior}{{9}{11}{The Normal-Gamma prior under different hyper-parameter initialisations.\relax }{figure.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The estimates for the hyper-parameters of the prior and posterior Normal-Gamma distributions\relax }}{11}{table.caption.17}\protected@file@percent }
\newlabel{tab:Q1_b}{{2}{11}{The estimates for the hyper-parameters of the prior and posterior Normal-Gamma distributions\relax }{table.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The log Normal-Gamma prior and the Normal-Gamma prior in its initial state. The initial parameters are: $a_0 = 1, b_0 = 1, \theta _0 = 0, \lambda _0 = 3$.\relax }}{12}{figure.caption.14}\protected@file@percent }
\newlabel{fig:Q1b_initial_prior}{{10}{12}{The log Normal-Gamma prior and the Normal-Gamma prior in its initial state. The initial parameters are: $a_0 = 1, b_0 = 1, \theta _0 = 0, \lambda _0 = 3$.\relax }{figure.caption.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The estimates for the model parameters $\theta $ and $\lambda $ using maximum likelihood and maximum a posteriori estimation. The MAP estimates were found through numerical optimisation.\relax }}{12}{table.caption.18}\protected@file@percent }
\newlabel{tab:Q1_c}{{3}{12}{The estimates for the model parameters $\theta $ and $\lambda $ using maximum likelihood and maximum a posteriori estimation. The MAP estimates were found through numerical optimisation.\relax }{table.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The resulting MAP estimates for $\theta $ and $\lambda $ for each of the prior hyper-parameters.\relax }}{13}{figure.caption.15}\protected@file@percent }
\newlabel{fig:Q1b_param_invest}{{11}{13}{The resulting MAP estimates for $\theta $ and $\lambda $ for each of the prior hyper-parameters.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The prior and posterior Normal-Gamma distributions. The parameters for these distributions are given in Table \ref  {tab:Q1_b}.\relax }}{13}{figure.caption.19}\protected@file@percent }
\newlabel{fig:Q1b_prior_posterior}{{12}{13}{The prior and posterior Normal-Gamma distributions. The parameters for these distributions are given in Table \ref {tab:Q1_b}.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The posterior marginal distributions for $\theta $ and $\lambda $.\relax }}{14}{figure.caption.20}\protected@file@percent }
\newlabel{fig:Q1b_marginals}{{13}{14}{The posterior marginal distributions for $\theta $ and $\lambda $.\relax }{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The posterior predictive distribution $p(x \vert \mathbf  {x})$ for the Bayesian conjugate prior inference process.\relax }}{14}{figure.caption.21}\protected@file@percent }
\newlabel{fig:Q1b_post_predict}{{14}{14}{The posterior predictive distribution $p(x \vert \mathbf {x})$ for the Bayesian conjugate prior inference process.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The CDFs used to determine the probabilities $p(\theta \leq 4 \vert \mathbf  {x})$ and $p(x \leq 4 \vert \mathbf  {x})$. In a) the CDF of the posterior distribution $p(\theta \vert \mathbf  {x})$ is shown, while in b) the CDF of the posterior predictive distribution $p(x \vert \mathbf  {x})$ is shown.\relax }}{14}{figure.caption.23}\protected@file@percent }
\newlabel{fig:Q1b_CDFs}{{15}{14}{The CDFs used to determine the probabilities $p(\theta \leq 4 \vert \mathbf {x})$ and $p(x \leq 4 \vert \mathbf {x})$. In a) the CDF of the posterior distribution $p(\theta \vert \mathbf {x})$ is shown, while in b) the CDF of the posterior predictive distribution $p(x \vert \mathbf {x})$ is shown.\relax }{figure.caption.23}{}}
\abx@aux@read@bbl@mdfivesum{5D0D039BF84E4F45A7144D280F172F5D}
\gdef \@abspage@last{14}
