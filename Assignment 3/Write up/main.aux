\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{none/global//global/global}
\@writefile{toc}{\contentsline {section}{\numberline {1}Question 1}{1}{section.1}\protected@file@percent }
\newlabel{eq:Q1_distribution}{{1}{1}{Question 1}{equation.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The distribution in Equation \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:Q1_distribution}\unskip \@@italiccorr )}} visualised over $x \in [-50, 50]$.\relax }}{1}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Q1_distribution}{{1}{1}{The distribution in Equation \eqref {eq:Q1_distribution} visualised over $x \in [-50, 50]$.\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The efficiency of the rejection sampling procedure for 1000 samples under different parametrisations of the proposal distribution $q(x)$. Note that as the scale parameter $k$ was determined automatically, the starting points for each of the different distributions is not consistent.\relax }}{3}{figure.caption.3}\protected@file@percent }
\newlabel{fig:Q1_rejection_sampling_dists}{{2}{3}{The efficiency of the rejection sampling procedure for 1000 samples under different parametrisations of the proposal distribution $q(x)$. Note that as the scale parameter $k$ was determined automatically, the starting points for each of the different distributions is not consistent.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The samples from $p(x)$ using rejection sampling and a proposal distribution $\text  {st}_{2}(x \vert 3, 5)$. \relax }}{3}{figure.caption.4}\protected@file@percent }
\newlabel{fig:Q1_rejection_sampling_samples}{{3}{3}{The samples from $p(x)$ using rejection sampling and a proposal distribution $\text {st}_{2}(x \vert 3, 5)$. \relax }{figure.caption.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces The estimates of interest using the samples of $p(x)$ obtained using rejection sampling.\relax }}{4}{table.caption.5}\protected@file@percent }
\newlabel{tab:Q1_estimates}{{1}{4}{The estimates of interest using the samples of $p(x)$ obtained using rejection sampling.\relax }{table.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The effect of the number of samples on the estimates. (a) shows the variation in the estimate and (b) shows the estimate error as a function of the number of samples. Note that the estimates were obtained as a once-off result, and as such this figure does not effectively convey the variation in the estimates for a given number of samples. However, it is clear that increasing the number of samples reduces the error in the estimates.\relax }}{4}{figure.caption.6}\protected@file@percent }
\newlabel{fig:Q1_estimate_error}{{4}{4}{The effect of the number of samples on the estimates. (a) shows the variation in the estimate and (b) shows the estimate error as a function of the number of samples. Note that the estimates were obtained as a once-off result, and as such this figure does not effectively convey the variation in the estimates for a given number of samples. However, it is clear that increasing the number of samples reduces the error in the estimates.\relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Question 2}{5}{section.2}\protected@file@percent }
\newlabel{eq:unnormalised_posterior}{{10}{6}{Question 2}{equation.2.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The prior, likelihood function and the unnormalised posterior for the second problem.\relax }}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:Q2_distributions}{{5}{6}{The prior, likelihood function and the unnormalised posterior for the second problem.\relax }{figure.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces The acceptance ratio and the estimates of interest for different proposal distributions with different initial parameters. Note that the estimates do not effectively capture the variation in the value of the estimates, and hence are biased as they were determined once off. A tuning period of $50\%$, a thinning size of 10, and 100 000 iterations were performed for all experiments.\relax }}{7}{table.caption.8}\protected@file@percent }
\newlabel{tab:Q2_results}{{2}{7}{The acceptance ratio and the estimates of interest for different proposal distributions with different initial parameters. Note that the estimates do not effectively capture the variation in the value of the estimates, and hence are biased as they were determined once off. A tuning period of $50\%$, a thinning size of 10, and 100 000 iterations were performed for all experiments.\relax }{table.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The effect of the number of samples on the MCMC-based estimates. (a) shows the variation in the estimate and (b) shows the estimate error as a function of the number of samples. Note that the estimates were obtained as a once-off result, and as such this figure does not effectively convey the variation in the estimates for a given number of samples. However, it is clear that increasing the number of samples reduces the error in the estimates. A Gaussian distribution with a mean of 0 and a variance of $2^2$ was used for all iterations.\relax }}{7}{figure.caption.9}\protected@file@percent }
\newlabel{fig:Q2_estimate_error}{{6}{7}{The effect of the number of samples on the MCMC-based estimates. (a) shows the variation in the estimate and (b) shows the estimate error as a function of the number of samples. Note that the estimates were obtained as a once-off result, and as such this figure does not effectively convey the variation in the estimates for a given number of samples. However, it is clear that increasing the number of samples reduces the error in the estimates. A Gaussian distribution with a mean of 0 and a variance of $2^2$ was used for all iterations.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Question 3}{8}{section.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The observed material data for the third problem.\relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:Q3_observed_data}{{7}{8}{The observed material data for the third problem.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}PyMC3 analysis}{8}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Application and inference}{9}{subsection.3.2}\protected@file@percent }
\newlabel{eq:predefined_posterior}{{17}{9}{Application and inference}{equation.3.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Samples from the prior and posterior distributions over $\{\tilde  {\bm  {\theta }}, \eta \}$.\relax }}{10}{figure.caption.11}\protected@file@percent }
\newlabel{fig:Q3_pymc3_prior_post_samples}{{8}{10}{Samples from the prior and posterior distributions over $\{\tilde {\boldsymbol \theta }, \eta \}$.\relax }{figure.caption.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Samples from the prior and posterior predictive distributions for the linear elasticity-linear hardening material model using the prior and posterior distribution \texttt  {PyMC3} samples.\relax }}{11}{figure.caption.12}\protected@file@percent }
\newlabel{fig:Q3_pymc3_prior_post_predictive_samples}{{9}{11}{Samples from the prior and posterior predictive distributions for the linear elasticity-linear hardening material model using the prior and posterior distribution \texttt {PyMC3} samples.\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Samples from the prior and posterior predictive distributions for the linear elasticity-linear hardening material model obtained using \texttt  {PyMC3}.\relax }}{11}{figure.caption.13}\protected@file@percent }
\newlabel{fig:Q3_pymc3_prior_post_predictive_PyMC3}{{10}{11}{Samples from the prior and posterior predictive distributions for the linear elasticity-linear hardening material model obtained using \texttt {PyMC3}.\relax }{figure.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The effect of the prior hyper-parameters on the MAP estimates of the model hyper-parameters.\relax }}{11}{figure.caption.14}\protected@file@percent }
\newlabel{fig:Q3_hyperparameter_effects}{{11}{11}{The effect of the prior hyper-parameters on the MAP estimates of the model hyper-parameters.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The likelihood and log-likelihood function for $E = 200 GPa, \sigma _{y_0} = 300 MPa, H = 45 GPa$ and an unknown noise.\relax }}{12}{figure.caption.15}\protected@file@percent }
\newlabel{fig:Q3_noise_LL}{{12}{12}{The likelihood and log-likelihood function for $E = 200 GPa, \sigma _{y_0} = 300 MPa, H = 45 GPa$ and an unknown noise.\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Samples from the marginal distribution $ p(\sigma _{y_0} \vert \bm  {\sigma }_{meas}, \bm  {\epsilon })$ over the yield stress.\relax }}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:Q3_yield}{{13}{13}{Samples from the marginal distribution $ p(\sigma _{y_0} \vert \boldsymbol \sigma _{meas}, \boldsymbol \epsilon )$ over the yield stress.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The empirical posterior predictive distribution where $\epsilon = 0.001$ for three different variations of the posterior predictive distribution.\relax }}{14}{figure.caption.17}\protected@file@percent }
\newlabel{fig:Q3_post_predict_samples}{{14}{14}{The empirical posterior predictive distribution where $\epsilon = 0.001$ for three different variations of the posterior predictive distribution.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Question 4}{15}{section.4}\protected@file@percent }
\newlabel{eq:poor_assumption}{{36}{16}{Question 4}{equation.4.36}{}}
\newlabel{eq:speed}{{37}{17}{Question 4}{equation.4.37}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Investigation 1}{17}{subsection.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The results for the naive speed estimation problem (equispaced increments) versus the unique solution case.\relax }}{17}{figure.caption.18}\protected@file@percent }
\newlabel{fig:Q4_constant}{{15}{17}{The results for the naive speed estimation problem (equispaced increments) versus the unique solution case.\relax }{figure.caption.18}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Investigation 2}{17}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces The actual angular increment sizes used for the speed estimation comparison problem.\relax }}{18}{figure.caption.19}\protected@file@percent }
\newlabel{fig:Q4_increments}{{16}{18}{The actual angular increment sizes used for the speed estimation comparison problem.\relax }{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces The actual speed profiles for the considered problem.\relax }}{19}{figure.caption.20}\protected@file@percent }
\newlabel{fig:Q4_profiles}{{17}{19}{The actual speed profiles for the considered problem.\relax }{figure.caption.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces The total squared error between the actual section angular increment size and the estimated size.\relax }}{19}{table.caption.24}\protected@file@percent }
\newlabel{tab:total_squared_error}{{3}{19}{The total squared error between the actual section angular increment size and the estimated size.\relax }{table.caption.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Investigation 3}{19}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The estimated shaft profiles for the process I attempted. Notice how each profile has a section in the beginning that is constant. This is a result of the assumption in Equation \textup  {\hbox {\mathsurround \z@ \normalfont  (\ignorespaces \ref  {eq:poor_assumption}\unskip \@@italiccorr )}}.\relax }}{20}{figure.caption.21}\protected@file@percent }
\newlabel{fig:Q4_estimated_profiles_me}{{18}{20}{The estimated shaft profiles for the process I attempted. Notice how each profile has a section in the beginning that is constant. This is a result of the assumption in Equation \eqref {eq:poor_assumption}.\relax }{figure.caption.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The estimated shaft profiles for the process presented in [CITE].\relax }}{21}{figure.caption.22}\protected@file@percent }
\newlabel{fig:Q4_estimated_profiles_BGC}{{19}{21}{The estimated shaft profiles for the process presented in [CITE].\relax }{figure.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces The section angular increment sizes for the four profiles analysed.\relax }}{22}{figure.caption.23}\protected@file@percent }
\newlabel{fig:Q4_sections}{{20}{22}{The section angular increment sizes for the four profiles analysed.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces The estimated speed profiles and angular increments for the \texttt  {uniquely solvable} and BGC procedures. Note that the naive speed profile, obtained using the assumption that each of the sections are equi-spaced, is plotted in blue in both of the sub-plots in (a).\relax }}{23}{figure.caption.25}\protected@file@percent }
\newlabel{fig:Q4_actual_signal_comparison}{{21}{23}{The estimated speed profiles and angular increments for the \texttt {uniquely solvable} and BGC procedures. Note that the naive speed profile, obtained using the assumption that each of the sections are equi-spaced, is plotted in blue in both of the sub-plots in (a).\relax }{figure.caption.25}{}}
\abx@aux@read@bbl@mdfivesum{D41D8CD98F00B204E9800998ECF8427E}
\gdef \@abspage@last{23}
